{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding and removal of cars after tracking (using iou)\n",
    "# detect only vehicles\n",
    "# detection using tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import imutils\n",
    "import time\n",
    "from sklearn.metrics import pairwise\n",
    "from imutils.video import FPS\n",
    "import copy\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "from utils import ops as utils_ops\n",
    "from utils import label_map_util\n",
    "\n",
    "\n",
    "\n",
    "utils_ops.tf = tf.compat.v1\n",
    "tf.gfile = tf.io.gfile\n",
    "PATH_TO_LABELS = '../bigdata/data/mscoco_label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_name = 'ssdlite_mobilenet_v2_coco_2018_05_09'\n",
    "model_dir =  \"../bigdata/models/\" + model_name + \"/saved_model\"\n",
    "detection_model = tf.saved_model.load(str(model_dir))\n",
    "detection_model = detection_model.signatures['serving_default']\n",
    "\n",
    "\n",
    "\n",
    "# print(category_index)\n",
    "colors = np.random.uniform(0, 255, size=(len(category_index), 3))\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "print(detection_model.inputs)\n",
    "print(detection_model.output_dtypes)\n",
    "print(detection_model.output_shapes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def iou(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    # compute the area of both the prediction and ground-truth rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    # print(interArea, float(boxAArea + boxBArea - interArea))\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    return iou\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def visualize(output_dict,image_np,height,width):\n",
    "  class_ids = []\n",
    "  confidences = []\n",
    "  boxes = []\n",
    "  num = output_dict['num_detections']\n",
    "  for ind in range(num):\n",
    "    scr = output_dict['detection_scores'][ind]\n",
    "    classId = output_dict['detection_classes'][ind] \n",
    "    box = output_dict['detection_boxes'][ind]\n",
    "\n",
    "    ymin, xmin, ymax, xmax = box\n",
    "    confidences.append(float(scr))\n",
    "    class_ids.append(classId)\n",
    "    boxes.append([int(xmin*width) , int(ymin*height) , int((xmax-xmin)*width) , int((ymax-ymin)*height)])\n",
    "\n",
    "  indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "  # if len(boxes) != len(indexes):\n",
    "  #   print(indexes,boxes , confidences,class_ids)\n",
    "  for j in indexes:\n",
    "    i = j[0]\n",
    "    x, y, w, h = boxes[i]\n",
    "    label = category_index[class_ids[i]]['name']\n",
    "    color = colors[i]\n",
    "    cv2.rectangle(image_np, (x, y), (x + w, y + h), color, 3)\n",
    "    cv2.putText(image_np, label, (x, y - 5), font, 3, color, 3)\n",
    "  # return image_np\n",
    "\n",
    "\n",
    "\n",
    "def run_inference_for_single_image(model, image):\n",
    "  image = np.asarray(image)\n",
    "  input_tensor = tf.convert_to_tensor(image)\n",
    "  input_tensor = input_tensor[tf.newaxis,...]\n",
    "\n",
    "  # output_dict is a dict  with keys detection_classes , num_detections , detection_boxes(4 coordinates of each box) , detection_scores for 100 boxes\n",
    "  output_dict = model(input_tensor)\n",
    "\n",
    "\n",
    "  # num_detections gives number of objects in current frame\n",
    "  num_detections = int(output_dict.pop('num_detections'))\n",
    "  # output_dict is a dict  with keys detection_classes , detection_boxes(4 coordinates of each box) , detection_scores for num_detections boxes\n",
    "  output_dict = {key:value[0, :num_detections].numpy() \n",
    "                 for key,value in output_dict.items()}\n",
    "  # adding num_detections that was earlier popped out\n",
    "  output_dict['num_detections'] = num_detections\n",
    "  # converting all values in detection_classes as ints.\n",
    "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
    "  # print(5,output_dict)\n",
    "\n",
    "  return output_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def show_inference(model, image_path):\n",
    "    image_np = np.array(image_path)\n",
    "    height,width,channel = image_np.shape\n",
    "\n",
    "    # Actual detection.\n",
    "    output_dict = run_inference_for_single_image(model, image_np)\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    num = output_dict['num_detections']\n",
    "    for ind in range(num):\n",
    "        classId = output_dict['detection_classes'][ind] \n",
    "        if classId==2 or classId==3 or classId==4 or classId==6 or classId==8:\n",
    "            scr = output_dict['detection_scores'][ind]\n",
    "            box = output_dict['detection_boxes'][ind]\n",
    "            ymin, xmin, ymax, xmax = box\n",
    "            w = (xmax - xmin) * width\n",
    "            h = (ymax - ymin) * height\n",
    "            if (w*h >=800):\n",
    "                boxes.append([xmin , ymin , w , h])\n",
    "                confidences.append(float(scr))\n",
    "                class_ids.append(classId)\n",
    "\n",
    "    indexesVehicles = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    change=[]\n",
    "    curr_frame=[]\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexesVehicles:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            # color = colors[i]\n",
    "            # cx,cy = (2*x + w)/2  ,  (2*y + h)/2\n",
    "            curr_frame.append([x,y,x+w,y+h,label])\n",
    "\n",
    "    # object tracking \n",
    "    curr , prev=copy.deepcopy(curr_frame) , copy.deepcopy(prev_frame)\n",
    "    display=[]\n",
    "    ll1,ll2,l1,l2=[],[],[],[]\n",
    "    ans=0\n",
    "    for i in range(max([len(prev_frame),len(curr_frame)])):\n",
    "        small=0\n",
    "        for curr_ind,curr_obj in enumerate(curr):\n",
    "            # x2 , y2 = curr_obj[4] , curr_obj[5]\n",
    "            l1 = [ curr_obj[0], curr_obj[1], curr_obj[2], curr_obj[3] ]\n",
    "            for prev_ind,prev_obj in enumerate(prev):\n",
    "                # x1 , y1 = prev_obj[0] , prev_obj[1]\n",
    "                l2 = [ prev_obj[0], prev_obj[1], prev_obj[2], prev_obj[3] ]\n",
    "                ans = iou( l1 , l2 )\n",
    "                # ans=((x2-x1)**2+(y2-y1)**2)**(1/2)\n",
    "                if ans > small:\n",
    "                    small = ans\n",
    "                    ll1,ll2=l1,l2\n",
    "                    ind = prev_obj[4]\n",
    "                    chct = prev_obj[5]\n",
    "                    # aa,bb,cc,dd=x1,y1,x2,y2\n",
    "                    pop1 , pop2 = curr_ind , prev_ind\n",
    "                    new_list = [ curr_obj[0], curr_obj[1], curr_obj[2], curr_obj[3] , ind ]\n",
    "                    disp=curr_obj\n",
    "        # print(small,aa,bb,cc,dd)\n",
    "        print(curr,prev)\n",
    "        print(small,ll1,ll2)\n",
    "        print(len(curr_frame) , len(prev_frame) , len(curr) , len(prev))\n",
    "        # print(min([len(prev_frame),len(curr_frame)]))\n",
    "        if small > 0.45:                   # decrease this if objects are small and their iou can change to a greater extent\n",
    "            display.append([disp,ind,chct])\n",
    "            curr.pop(pop1)\n",
    "            prev.pop(pop2)\n",
    "            change.append(new_list)\n",
    "        else:\n",
    "            break\n",
    "        print(len(change),len(display))\n",
    "\n",
    "    print('display curr',display,curr)       \n",
    "    for i in display:\n",
    "        color=colors[i[1]%75]\n",
    "        x1,y1,x2,y2,label = i[0][0] , i[0][1] , i[0][2] , i[0][3] , i[0][4] \n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "        text=' '+str(i[1]) \n",
    "        cv2.putText(img, text, (x1, y1 + 30), font, 3, color, 2)\n",
    "\n",
    "    for i in curr:\n",
    "        number=number+1\n",
    "        color=colors[number%75]\n",
    "        prev_frame.append([i[0], i[1], i[2], i[3], number,0])\n",
    "        x1, y1, x2, y2, label = i[0] , i[1] , i[2] , i[3] , i[4] \n",
    "\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "        text=' '+str(number)\n",
    "        cv2.putText(img, text, (x1, y1 + 30), font, 3, color, 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if number==0:\n",
    "        for i in curr_frame:\n",
    "            number=number+1\n",
    "            color=colors[number%75]\n",
    "            xx1, yy1, xx2, yy2, label = i\n",
    "            prev_frame.append([xx1, yy1, xx2, yy2, number, 0])\n",
    "\n",
    "            cv2.rectangle(img, (xx1, yy1), (xx2, yy2), color, 2)\n",
    "            text=' '+str(number)\n",
    "            cv2.putText(img, text, (xx1, yy1 + 30), font, 3, color, 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # print(number , len(prev_frame),len(curr_frame))\n",
    "    print()\n",
    "    for ch in change:\n",
    "        find=ch[4]\n",
    "        for rr,ob in enumerate(prev_frame):\n",
    "            if ob[4]==find:\n",
    "                prev_frame[rr][0], prev_frame[rr][1], prev_frame[rr][2], prev_frame[rr][3], prev_frame[rr][5] = ch[0], ch[1], ch[2], ch[3], 0\n",
    "                break\n",
    "\n",
    "\n",
    "    index_note=[]\n",
    "    for rr,ob in enumerate(prev_frame):\n",
    "        prev_frame[rr][5]+=1\n",
    "        if prev_frame[rr][5]>=6:\n",
    "            index_note.append(rr)\n",
    "    print(\"prev_frame\",prev_frame)\n",
    "    print(index_note)\n",
    "    lll=[]\n",
    "    for rr,ob in enumerate(prev_frame):\n",
    "        flag=0\n",
    "        for j in index_note:\n",
    "            if j==rr:\n",
    "                flag=1\n",
    "                break\n",
    "        if flag==0:\n",
    "            lll.append(ob)\n",
    "    prev_frame=lll\n",
    "    print('after pop',prev_frame)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # visualize(output_dict,image_np,height,width)\n",
    "    cv2.imshow(\"version\", image_np)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# cap=cv2.VideoCapture(0)\n",
    "cap=cv2.VideoCapture('../videos/highway.mp4')\n",
    "time.sleep(2.0)\n",
    "\n",
    "cap.set(1,0)\n",
    "\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "# out1 = cv2.VideoWriter('i.avi', fourcc, 3.0, (int(cap.get(3)),int(cap.get(4))))\n",
    "\n",
    "fps = FPS().start()\n",
    "ctt = 0\n",
    "prev_frame=[]\n",
    "number=0\n",
    "cot=0\n",
    "while True:\n",
    "    _,frame=cap.read()\n",
    "    height, width, channels = frame.shape\n",
    "\n",
    "    show_inference(detection_model, frame)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    cv2.imshow(\"version\", frame)\n",
    "    # out1.write(frame)\n",
    "    fps.update()\n",
    "\n",
    "    key=cv2.waitKey(100)\n",
    "    if key & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "        \n",
    "# stop the timer and display FPS information\n",
    "fps.stop()\n",
    "print(\"[INFO] elasped time: {:.2f}\".format(fps.elapsed()))\n",
    "print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "cap.release()\n",
    "# out1.release()\n",
    "cv2.destroyAllWindows() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
